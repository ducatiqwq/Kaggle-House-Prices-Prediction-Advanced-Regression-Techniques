{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入必要模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyper\n",
    "import time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Union, Literal\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import RobustScaler, PowerTransformer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\t\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression\n",
    "from hyper import printLog, boot, getTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\").drop(columns=[\"Id\"])\n",
    "test_data = pd.read_csv(\"data/test.csv\").drop(columns=[\"Id\"])\n",
    "all_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "printLog(\"Shape:\", all_data.shape)\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 杂项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(hyper.RANDOM_STATE)\n",
    "sns.set_theme()\n",
    "boot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征分析与处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关系数分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coef = train_data.corr(\"pearson\", numeric_only=True)\n",
    "if hyper.DISPLAY_CORR_FIGURE:\n",
    "\tplt.figure(figsize=(10, 10))\n",
    "\tsns.heatmap(corr_coef, square=True, cmap=\"rocket_r\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据类型更改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[hyper.DTYPE_CONVERT_LIST] = all_data[hyper.DTYPE_CONVERT_LIST].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 封装填充函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceNull(arr: pd.Series,\n",
    "\t\t\t\ttyp: str,\n",
    "\t\t\t\tmsg: Union[int, str, None] = None) -> pd.Series:\n",
    "\t\"\"\"Process the column in a specific mode.\"\"\"\n",
    "\tif typ == \"const\":\n",
    "\t\tresult = arr.fillna(msg)\n",
    "\telif typ == \"mode\":\n",
    "\t\tmode = arr.mode()[0]\n",
    "\t\tresult = arr.fillna(mode)\n",
    "\telif typ == \"median\":\n",
    "\t\tmedian = arr.median()\n",
    "\t\tresult = arr.fillna(median)\n",
    "\telif typ == \"mean\":\n",
    "\t\tmean = arr.mean()\n",
    "\t\tresult = arr.fillna(mean)\n",
    "\telif typ == \"random\":\n",
    "\t\tisnull = arr.isnull()\n",
    "\t\tfilled = arr[~isnull]\n",
    "\t\tresult = arr[isnull].transform(lambda x: filled.sample(1).item())\n",
    "\t\tresult = pd.concat([result, filled])\n",
    "\telse:\n",
    "\t\traise KeyError(\"Illegal replace mode.\")\n",
    "\treturn result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 删除严重缺失特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_missed = all_data.isnull().sum(axis=0)\n",
    "for key, cnt in cnt_missed.items():\n",
    "\tif cnt == 0:\n",
    "\t\tcontinue\n",
    "\trate = cnt / all_data.shape[0]\n",
    "\tif rate >= hyper.UNACCEPTABLE_MISSED_RATE:\n",
    "\t\tall_data.drop(key, axis=1, inplace=True)\n",
    "\t\tprintLog(f\"Drop key: {key}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 缺失值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, operation in hyper.REPLACE_MODES.items():\n",
    "\tmode: str = operation[0]\n",
    "\tif mode == \"group\":\n",
    "\t\tgroup_name: str = operation[1]\n",
    "\t\tsubmode: str = operation[2]\n",
    "\t\tall_data[key] = all_data.groupby(group_name)[key].transform(lambda group: replaceNull(group, submode))\n",
    "\telse:\n",
    "\t\tmsg = operation[1]\n",
    "\t\tall_data[key] = replaceNull(all_data[key], mode, msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 核查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(not all_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 极端样本处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 极端样本挖掘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOutliers(key1: str, key2: str, val: float) -> None:\n",
    "\tfig = plt.figure(figsize=(10, 10))\n",
    "\tplt.title(f\"key1 = {key1}, key2 = {key2}, val = {val}\")\n",
    "\tplt.xlabel(key1)\n",
    "\tplt.ylabel(key2)\n",
    "\tplt.plot(all_data[key1], all_data[key2], \"bo\", alpha=0.2)\n",
    "\tfor id, (x, y) in enumerate(zip(all_data[key1], all_data[key2])):\n",
    "\t\tplt.text(x, y, str(id), fontsize='x-small')\n",
    "\tplt.show()\n",
    "if hyper.ENABLE_OUTLIERS_DISCOVERY:\n",
    "\tcorr_with_target = corr_coef[hyper.TARGET].drop(hyper.TARGET)\n",
    "\tcorr_with_target.sort_values(ascending=False, inplace=True)\n",
    "\tfor key, val in corr_with_target.items():\n",
    "\t\tfindOutliers(str(key), hyper.TARGET, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 极端样本删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drop_list in hyper.DROP_LISTS:\n",
    "\tfor drop_id in drop_list:\n",
    "\t\t# Ensure that no duplicate drop_ids exist\n",
    "\t\tif drop_id in all_data.index:\n",
    "\t\t\tall_data.drop(index=[drop_id], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测目标改进"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHistogram() -> None:\n",
    "\tif hyper.DISPLAY_TARGET_HISTOGRAM:\n",
    "\t\tfig = plt.figure(figsize=(6, 6))\n",
    "\t\tsns.histplot(all_data.loc[:, [hyper.TARGET]])\n",
    "\t\tplt.show()\n",
    "all_data[hyper.TARGET] = np.log1p(all_data[hyper.TARGET])\n",
    "showHistogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高偏特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [key for key in all_data.columns if pd.api.types.is_numeric_dtype(all_data[key]) and key != hyper.TARGET]\n",
    "def print_skews():\n",
    "\tif hyper.PRINT_SKEWS:\n",
    "\t\tfor key in numeric_columns:\n",
    "\t\t\tassert(not all_data[key].isnull().sum())\n",
    "\t\t\tprintLog(key, all_data[key].min(), all_data[key].max(), skew(all_data[key]))\n",
    "\n",
    "transformer = make_pipeline(StandardScaler(), PowerTransformer())\n",
    "all_data[numeric_columns] = transformer.fit_transform(all_data[numeric_columns])\n",
    "print_skews()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['YrRemodAfterBuilt'] = all_data['YearRemodAdd'] - all_data['YearBuilt']\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "all_data['Total_sqr_footage'] = (all_data['BsmtFinSF1'] + all_data['BsmtFinSF2'] + all_data['1stFlrSF'] + all_data['2ndFlrSF'])\n",
    "all_data['Total_Bathrooms'] = (all_data['FullBath'] + (0.5 * all_data['HalfBath']) + all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath']))\n",
    "all_data['Total_porch_sf'] = (all_data['OpenPorchSF'] + all_data['3SsnPorch'] +\n",
    "\t\t\t\t\t\t\t  all_data['EnclosedPorch'] + all_data['ScreenPorch'] +\n",
    "\t\t\t\t\t\t\t  all_data['WoodDeckSF'])\n",
    "all_data = all_data.drop(\"TotalBsmtSF\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxProps() -> list:\n",
    "\tmax_occs_series: pd.Series = all_data.apply(lambda feature: (feature.value_counts().max() / len(feature),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfeature.name),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tresult_type=\"reduce\")\n",
    "\toccs = sorted(max_occs_series.to_numpy().tolist(), key=lambda tuple: tuple[0], reverse=True)\n",
    "\treturn occs\n",
    "max_props = getMaxProps()\n",
    "for prop, key in max_props:\n",
    "\tif key != hyper.TARGET and prop >= hyper.MINIMUM_MONOTONOUS_PROPOTION:\n",
    "\t\tmode = all_data[key].mode()[0]\n",
    "\t\tall_data[key] = all_data[key].apply(lambda x: x == mode)\n",
    "\t\tprintLog(f\"Simplify {key} by {mode} with proportion = {prop * 100 :>.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征拆解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过拟合列删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_keys = []\n",
    "max_props = getMaxProps()\n",
    "for prop, key in max_props:\n",
    "\tif prop > hyper.MINIMUM_ABANDONED_PROPOTION:\n",
    "\t\tprintLog(f\"Drop overfitting feature {key}.\")\n",
    "\t\tdropped_keys.append(key)\n",
    "all_data.drop(columns=dropped_keys, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型建立、训练与融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data.loc[0: 1459]\n",
    "train_features = train_data.drop(columns=hyper.TARGET)\n",
    "train_labels = train_data[hyper.TARGET]\n",
    "\n",
    "test_data = all_data.loc[1460: ]\n",
    "test_features = test_data.drop(columns=hyper.TARGET)\n",
    "\n",
    "train_data.shape\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolder = KFold(hyper.CNT_FOLDS, shuffle=True, random_state=hyper.RANDOM_STATE)\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(), memory=\"cache\")\n",
    "gbr = make_pipeline(GradientBoostingRegressor(), memory=\"cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidationTrain(model: Pipeline, param_grid: dict) -> None:\n",
    "\tbegin_time = time.time()\n",
    "\tprintLog(f\"Working on {type(model).__name__}...\", to_logs=True)\n",
    "\n",
    "\tgrid_searcher = GridSearchCV(model, param_grid, cv=hyper.CNT_FOLDS, scoring=\"neg_mean_squared_error\", refit=False, error_score=\"raise\")\n",
    "\tgrid_searcher.fit(train_features.copy(), train_labels.copy())\n",
    "\t# display(grid_searcher.cv_results_)\n",
    "\tprintLog(f\"Done, time consumed: {time.time() - begin_time :>.3f}s, score: {grid_searcher.best_score_}, best_param: {grid_searcher.best_params_}\",\n",
    "\t\t\t to_logs=True)\n",
    "\n",
    "if hyper.RIDGECV_EVAL:\n",
    "\tcrossValidationTrain(ridge, hyper.RIDGECV_PARAM_GRID)\n",
    "\n",
    "if hyper.GBR_EVAL:\t\n",
    "\tcrossValidationTrain(gbr, hyper.GBR_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最优超参数选择与模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyper.RIDGECV_TRAIN:\n",
    "\tridge = make_pipeline(RobustScaler(), RidgeCV(**hyper.RIDGECV_PARAM), memory=\"cache\")\t#type: ignore\n",
    "\tridge.fit(train_features, train_labels)\n",
    "\n",
    "if hyper.GBR_TRAIN:\n",
    "\tgbr = make_pipeline(GradientBoostingRegressor(**hyper.GBR_PARAM), memory=\"cache\")\n",
    "\tgbr.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyper.SUBMIT:\n",
    "\tdef makePrediction(model: Pipeline) -> np.ndarray:\n",
    "\t\tprediction = model.predict(test_features)\n",
    "\t\tprediction = np.expm1(prediction)\n",
    "\t\treturn prediction\n",
    "\n",
    "\ttest_prediction = makePrediction(ridge) * hyper.RIDGE_WEIGHT + makePrediction(gbr) * hyper.GRB_WEIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit() -> None:\n",
    "\tprintLog(\"Saving...\")\n",
    "\tsubmission_file = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "\tsubmission_file[hyper.TARGET] = test_prediction\n",
    "\tsubmission_file.to_csv(f\"submissions/{getTime(as_file_name=True)}.csv\", index=False)\n",
    "if hyper.SUBMIT:\n",
    "\tsubmit()\n",
    "printLog(\"All done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
